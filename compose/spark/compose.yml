services:
  # 1. NODO MAESTRO
  spark-master:
    image: spark:3.5.0-scala2.12-java11-python3-ubuntu
    container_name: spark-master
    ports:
      - "8080:8080" # Interfaz web de monitoreo
      - "7077:7077" # Puerto del master
      - "4040:4040"
      # - "15002:15002"
    environment:
      - SPARK_MODE=master
      - SPARK_PUBLIC_DNS=127.0.0.1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no # Simplificación para desarrollo
    command: [ "bash",  "-c", "/opt/spark/sbin/start-master.sh 
                && /opt/spark/sbin/start-connect-server.sh
                && tail -F /opt/spark/logs/*.out"]

  # 2. NODO TRABAJADOR
  spark-worker-1:
    image: spark:3.5.0-scala2.12-java11-python3-ubuntu
    container_name: spark-worker-1
    ports:
      - "8081:8081"
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    command: [ "bash", "-c", "/opt/spark/sbin/start-worker.sh spark://spark-master:7077 
                && tail -F /opt/spark/logs/*.out" ]
    depends_on:
      - spark-master

  # 3. CONTENEDOR DE CLIENTE/DRIVER (JupyterLab)
  jupyter-driver:
    build: 
      context: .             # Indica que el Dockerfile está en la misma carpeta
      dockerfile: Dockerfile # El nombre del archivo que creamos arriba
    container_name: jupyter-spark-driver
    ports:
      - "8899:8888" # Acceso a Jupyter
      # - "4040:4040" # Acceso a la UI de tu aplicación
    environment:
      # Apuntamos al master definido arriba
      - SPARK_MASTER=spark://spark-master:7077
    volumes:
      - ./work:/workspace # Monta tu carpeta local 'work' dentro del contenedor
    depends_on:
      - spark-master